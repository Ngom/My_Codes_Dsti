{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_practice_2.ipynb",
      "provenance": [],
      "mount_file_id": "1-g87y-clCRAez2ehKpVjShCgeWRZTaQq",
      "authorship_tag": "ABX9TyNaN42b8PygDW+UGAEozcLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ngom/My_Codes_Dsti/blob/main/ANN_practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8n8JghXU_JZc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authentitiate to acces to colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjnu725e_NSb",
        "outputId": "be36bc54-e25f-4983-d6fc-a44edd78f725"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3AHPH0k_1mG",
        "outputId": "acc90860-83af-4db3-bb16-1775860519d9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read and upload the data\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Churn_Modelling.csv\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "cYig-pWcAh91",
        "outputId": "52bba734-6d7a-40bc-b13c-59d05f257387"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "0             1    15634602   Hargrave          619    France  Female   42   \n",
              "1             2    15647311       Hill          608     Spain  Female   41   \n",
              "2             3    15619304       Onio          502    France  Female   42   \n",
              "3             4    15701354       Boni          699    France  Female   39   \n",
              "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
              "...         ...         ...        ...          ...       ...     ...  ...   \n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          2       0.00              1          1               1   \n",
              "1          1   83807.86              1          0               1   \n",
              "2          8  159660.80              3          1               0   \n",
              "3          1       0.00              2          0               0   \n",
              "4          2  125510.82              1          1               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           101348.88       1  \n",
              "1           112542.58       0  \n",
              "2           113931.57       1  \n",
              "3            93826.63       0  \n",
              "4            79084.10       0  \n",
              "...               ...     ...  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  \n",
              "\n",
              "[10000 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bbc1775-3469-41bf-a398-ab8a95660d96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bbc1775-3469-41bf-a398-ab8a95660d96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bbc1775-3469-41bf-a398-ab8a95660d96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bbc1775-3469-41bf-a398-ab8a95660d96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view column names\n",
        "print(dataset.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ayjaXJLC8uH",
        "outputId": "8c9e1530-0d73-4389-f151-a52bdc1ee138"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
            "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
            "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view the inxes\n",
        "print(dataset.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyUdwz68DFxX",
        "outputId": "5c1d372e-f475-4dca-d5cb-ccf59803de1a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=10000, step=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not all independent variables are not important for analysis such as RowNumber, CustomerID or Surname\n",
        "x = dataset.iloc[:, 3:13].values # consider data from column 3\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0YtQ6XcDZBw",
        "outputId": "df1fd75c-d5d0-458b-eca6-016cca023203"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the labels\n",
        "y = dataset.iloc[:,13].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5elMYTBEAUA",
        "outputId": "272e0b7b-0270-4c71-d2d0-f0928b2677cd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another to get label\n",
        "z = dataset['Exited']\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uORT3gMBE0mh",
        "outputId": "4fc71eea-536a-441d-d9a2-387470a17d5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################## DATA ENCODING ###################################\n",
        "# We have to encode categorical data such as Geography and Gender.\n",
        "\n",
        "#ORDINAL ENCODING : way 1\n",
        "# import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "X_ord_1 = dataset.iloc[:, 3:13].values # get the data in new varible name\n",
        "LabelEncoder_X = LabelEncoder()       # instanciate an object of the LabelEncoder\n",
        "X_ord_1[:,1] = LabelEncoder_X.fit_transform(X_ord_1[:,1]) # ordinal encoding for column 1\n",
        "X_ord_1[:,2] = LabelEncoder_X.fit_transform(X_ord_1[:,2]) # ordinal encoding for column 2\n",
        "X_ord_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKBGDVKGFxZ3",
        "outputId": "a60cf7f8-d085-471a-a2cc-f8218e55b96f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ORDINAL ENCODING - way 2 \n",
        "# problem or bug : it sets all to zero\n",
        "# import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal_encoder_1 = OrdinalEncoder()   # instanciate an object of the LabelEncoder\n",
        "X_ord_2 = dataset.iloc[:, 3:13].values # get the data in new varible name\n",
        "X_ord_2[:, 1] = ordinal_encoder_1.fit_transform([X_ord_2[:, 1]]) # ordinal encoding for column 1\n",
        "X_ord_2[:, 2] = ordinal_encoder_1.fit_transform([X_ord_2[:, 2]]) # ordinal encoding for column 1\n",
        "X_ord_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBD_byumLewF",
        "outputId": "a0f99cb0-e964-486a-c51c-8d0b34523805"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
              "       [608, 0.0, 0.0, ..., 0, 1, 112542.58],\n",
              "       [502, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
              "       [772, 0.0, 0.0, ..., 1, 0, 92888.52],\n",
              "       [792, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_ord_1"
      ],
      "metadata": {
        "id": "3s8L8W2mNDrm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################## ONE-HOT ENCODING ########################################\n",
        "# Way 1: using data values \n",
        "from sklearn.preprocessing import OneHotEncoder # import OneHot Encoder\n",
        "from sklearn.compose import ColumnTransformer   # get the Column Transformer\n",
        "import numpy as np\n",
        "\n",
        "ct = ColumnTransformer(                  # 'encoder' is the name of the column transformer\n",
        "    [('encoder', OneHotEncoder(), [1])], # the column numbers to be transformed (here [1] but can be like [1,2,3]) \n",
        "    remainder='passthrough'              # leave the rest rest untouch\n",
        ")\n",
        "# get transformed data\n",
        "X = np.array(ct.fit_transform(X), dtype=int) #Note: The X matrix should be ordinally encoded (with ordinal encoding applied to it)\n",
        "# convert data to data frame\n",
        "df = pd.DataFrame(X)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4-GPg8roNI73",
        "outputId": "6f14fcd7-453d-417f-ca9f-d9240851ba75"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0   1   2    3   4   5   6       7   8   9   10      11\n",
              "0      1   0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      1   0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      1   0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   1   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   1   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   1   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   0   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   1   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ede77c2-1b9c-4746-9ee3-a1878c6d446c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ede77c2-1b9c-4746-9ee3-a1878c6d446c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ede77c2-1b9c-4746-9ee3-a1878c6d446c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ede77c2-1b9c-4746-9ee3-a1878c6d446c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we remove the first column to avoid the dummy data drap\n",
        "X = X[:, 1:]\n",
        "df = pd.DataFrame(X)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2izK9ruHJ7ZX",
        "outputId": "3f03322e-d279-410e-96f6-278725c0213d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0   1    2   3   4   5       6   7   8   9       10\n",
              "0      0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89a298c0-8570-4f16-8527-a7d87088e912\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89a298c0-8570-4f16-8527-a7d87088e912')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89a298c0-8570-4f16-8527-a7d87088e912 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89a298c0-8570-4f16-8527-a7d87088e912');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get prefix module from sys library\n",
        "#from sys import prefix\n",
        "\n",
        "# ONE ENCODING way 2 : Unsing data frame\n",
        "X_df = dataset.iloc[:, 3:13]\n",
        "X_df = pd.concat([X_df, pd.get_dummies(X_df['Geography'], prefix='country', drop_first=True)], axis=1) # grops the first column\n",
        "# axis=1 means contenate along the the column (put column beside another)\n",
        "X_df.drop(['Geography'], axis=1, inplace=True) # get rig of the original column\n",
        "X_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qWbBXrzXQuhF",
        "outputId": "0de529c3-b2eb-455b-c0dc-fd4ac53410a7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0             619  Female   42       2       0.00              1          1   \n",
              "1             608  Female   41       1   83807.86              1          0   \n",
              "2             502  Female   42       8  159660.80              3          1   \n",
              "3             699  Female   39       1       0.00              2          0   \n",
              "4             850  Female   43       2  125510.82              1          1   \n",
              "...           ...     ...  ...     ...        ...            ...        ...   \n",
              "9995          771    Male   39       5       0.00              2          1   \n",
              "9996          516    Male   35      10   57369.61              1          1   \n",
              "9997          709  Female   36       7       0.00              1          0   \n",
              "9998          772    Male   42       3   75075.31              2          1   \n",
              "9999          792  Female   28       4  130142.79              1          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  country_Germany  country_Spain  \n",
              "0                  1        101348.88                0              0  \n",
              "1                  1        112542.58                0              1  \n",
              "2                  0        113931.57                0              0  \n",
              "3                  0         93826.63                0              0  \n",
              "4                  1         79084.10                0              1  \n",
              "...              ...              ...              ...            ...  \n",
              "9995               0         96270.64                0              0  \n",
              "9996               1        101699.77                0              0  \n",
              "9997               1         42085.58                0              0  \n",
              "9998               0         92888.52                1              0  \n",
              "9999               0         38190.78                0              0  \n",
              "\n",
              "[10000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4b03b7b-0ada-4eea-b3a8-5321c01d3679\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>country_Germany</th>\n",
              "      <th>country_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4b03b7b-0ada-4eea-b3a8-5321c01d3679')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4b03b7b-0ada-4eea-b3a8-5321c01d3679 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4b03b7b-0ada-4eea-b3a8-5321c01d3679');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data into training and testing sets\n",
        "- 80% train\n",
        "- 20% test"
      ],
      "metadata": {
        "id": "McS8RIL1LkuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # import spliter from sklearn\n",
        "# We use random_state when splitting to be sure having same data at each time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "qIPW-71FUvQ9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize train and test (x_standardized = (x - mean)/std_dev)\n",
        "from sklearn.preprocessing import StandardScaler # get Standardise scaler\n",
        "# instiate the sclaer\n",
        "sc = StandardScaler()\n",
        "# transform x train\n",
        "X_train = sc.fit_transform(X_train)\n",
        "# transform x test with the sacler of x train\n",
        "X_test = sc.transform(X_test) # transform instead of fit_trans\n",
        "df = pd.DataFrame(X_train)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FspKSNwJU0bt",
        "outputId": "98a40245-eb4e-476b-fd09-cdfe913b910d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  1.714901 -0.572731 -0.230820  0.915091 -0.944500 -0.701742  0.588164   \n",
              "1 -0.583124 -0.572731 -0.251509 -1.092788 -0.944500 -0.355203  0.469851   \n",
              "2  1.714901 -0.572731 -0.396330 -1.092788  0.774987  0.337876  0.858782   \n",
              "3  1.714901 -0.572731 -0.044622 -1.092788  1.252622  0.337876  0.565605   \n",
              "4 -0.583124  1.746019  0.658795  0.915091 -0.562392  1.030954  0.730400   \n",
              "\n",
              "         7         8         9         10  \n",
              "0  0.802257 -1.553374  0.977259  0.427402  \n",
              "1  0.802257 -1.553374 -1.023271 -1.025493  \n",
              "2 -0.911510  0.643760  0.977259 -0.944793  \n",
              "3  0.802257 -1.553374  0.977259 -0.551941  \n",
              "4 -0.911510 -1.553374 -1.023271  1.083388  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e778c4f5-67e8-4b88-a1f9-f6b612da073c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.230820</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.701742</td>\n",
              "      <td>0.588164</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>0.427402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.251509</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.355203</td>\n",
              "      <td>0.469851</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-1.025493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.396330</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.774987</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.858782</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.944793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.044622</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>1.252622</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.565605</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.551941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>1.746019</td>\n",
              "      <td>0.658795</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.562392</td>\n",
              "      <td>1.030954</td>\n",
              "      <td>0.730400</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>1.083388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e778c4f5-67e8-4b88-a1f9-f6b612da073c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e778c4f5-67e8-4b88-a1f9-f6b612da073c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e778c4f5-67e8-4b88-a1f9-f6b612da073c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the model"
      ],
      "metadata": {
        "id": "RdpGB5x2O623"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow and keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "5C0FKrnRXGQ_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model = keras.Sequential()\n",
        "# add first hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "# add second hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "# add the output layer\n",
        "model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "# sigmoid for binary on the ouptut layer\n",
        "# sotfmax for multiclass on the output layer"
      ],
      "metadata": {
        "id": "cP5PJx3BXW02"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QS29qD7RYjYl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(X_train, y_train, batch_size=10,epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io3FtUq-ZTKV",
        "outputId": "b652d8cd-9506-4f0f-fa9c-39d1fbcedc54"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "800/800 - 2s - loss: 0.4852 - accuracy: 0.7972 - 2s/epoch - 2ms/step\n",
            "Epoch 2/200\n",
            "800/800 - 1s - loss: 0.4282 - accuracy: 0.7972 - 1s/epoch - 1ms/step\n",
            "Epoch 3/200\n",
            "800/800 - 1s - loss: 0.4202 - accuracy: 0.8114 - 1s/epoch - 1ms/step\n",
            "Epoch 4/200\n",
            "800/800 - 1s - loss: 0.4129 - accuracy: 0.8331 - 973ms/epoch - 1ms/step\n",
            "Epoch 5/200\n",
            "800/800 - 1s - loss: 0.4086 - accuracy: 0.8341 - 960ms/epoch - 1ms/step\n",
            "Epoch 6/200\n",
            "800/800 - 1s - loss: 0.4052 - accuracy: 0.8336 - 939ms/epoch - 1ms/step\n",
            "Epoch 7/200\n",
            "800/800 - 1s - loss: 0.4034 - accuracy: 0.8370 - 932ms/epoch - 1ms/step\n",
            "Epoch 8/200\n",
            "800/800 - 1s - loss: 0.4014 - accuracy: 0.8370 - 962ms/epoch - 1ms/step\n",
            "Epoch 9/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8375 - 974ms/epoch - 1ms/step\n",
            "Epoch 10/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8372 - 1s/epoch - 1ms/step\n",
            "Epoch 11/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8381 - 977ms/epoch - 1ms/step\n",
            "Epoch 12/200\n",
            "800/800 - 1s - loss: 0.3980 - accuracy: 0.8375 - 943ms/epoch - 1ms/step\n",
            "Epoch 13/200\n",
            "800/800 - 1s - loss: 0.3977 - accuracy: 0.8354 - 979ms/epoch - 1ms/step\n",
            "Epoch 14/200\n",
            "800/800 - 1s - loss: 0.3972 - accuracy: 0.8385 - 939ms/epoch - 1ms/step\n",
            "Epoch 15/200\n",
            "800/800 - 1s - loss: 0.3970 - accuracy: 0.8375 - 955ms/epoch - 1ms/step\n",
            "Epoch 16/200\n",
            "800/800 - 1s - loss: 0.3968 - accuracy: 0.8372 - 983ms/epoch - 1ms/step\n",
            "Epoch 17/200\n",
            "800/800 - 1s - loss: 0.3962 - accuracy: 0.8391 - 992ms/epoch - 1ms/step\n",
            "Epoch 18/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8381 - 961ms/epoch - 1ms/step\n",
            "Epoch 19/200\n",
            "800/800 - 1s - loss: 0.3958 - accuracy: 0.8390 - 1s/epoch - 1ms/step\n",
            "Epoch 20/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8389 - 956ms/epoch - 1ms/step\n",
            "Epoch 21/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8400 - 969ms/epoch - 1ms/step\n",
            "Epoch 22/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8386 - 933ms/epoch - 1ms/step\n",
            "Epoch 23/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8385 - 990ms/epoch - 1ms/step\n",
            "Epoch 24/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8409 - 922ms/epoch - 1ms/step\n",
            "Epoch 25/200\n",
            "800/800 - 1s - loss: 0.3948 - accuracy: 0.8409 - 928ms/epoch - 1ms/step\n",
            "Epoch 26/200\n",
            "800/800 - 1s - loss: 0.3947 - accuracy: 0.8385 - 956ms/epoch - 1ms/step\n",
            "Epoch 27/200\n",
            "800/800 - 1s - loss: 0.3948 - accuracy: 0.8403 - 930ms/epoch - 1ms/step\n",
            "Epoch 28/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8394 - 934ms/epoch - 1ms/step\n",
            "Epoch 29/200\n",
            "800/800 - 1s - loss: 0.3947 - accuracy: 0.8388 - 952ms/epoch - 1ms/step\n",
            "Epoch 30/200\n",
            "800/800 - 1s - loss: 0.3945 - accuracy: 0.8386 - 939ms/epoch - 1ms/step\n",
            "Epoch 31/200\n",
            "800/800 - 1s - loss: 0.3948 - accuracy: 0.8399 - 1s/epoch - 1ms/step\n",
            "Epoch 32/200\n",
            "800/800 - 1s - loss: 0.3941 - accuracy: 0.8395 - 939ms/epoch - 1ms/step\n",
            "Epoch 33/200\n",
            "800/800 - 1s - loss: 0.3943 - accuracy: 0.8390 - 1s/epoch - 2ms/step\n",
            "Epoch 34/200\n",
            "800/800 - 2s - loss: 0.3945 - accuracy: 0.8406 - 2s/epoch - 2ms/step\n",
            "Epoch 35/200\n",
            "800/800 - 1s - loss: 0.3943 - accuracy: 0.8395 - 1s/epoch - 2ms/step\n",
            "Epoch 36/200\n",
            "800/800 - 1s - loss: 0.3944 - accuracy: 0.8395 - 1s/epoch - 2ms/step\n",
            "Epoch 37/200\n",
            "800/800 - 1s - loss: 0.3945 - accuracy: 0.8393 - 1s/epoch - 2ms/step\n",
            "Epoch 38/200\n",
            "800/800 - 1s - loss: 0.3943 - accuracy: 0.8397 - 1s/epoch - 1ms/step\n",
            "Epoch 39/200\n",
            "800/800 - 2s - loss: 0.3946 - accuracy: 0.8397 - 2s/epoch - 3ms/step\n",
            "Epoch 40/200\n",
            "800/800 - 1s - loss: 0.3943 - accuracy: 0.8404 - 1s/epoch - 1ms/step\n",
            "Epoch 41/200\n",
            "800/800 - 1s - loss: 0.3942 - accuracy: 0.8399 - 1s/epoch - 1ms/step\n",
            "Epoch 42/200\n",
            "800/800 - 2s - loss: 0.3943 - accuracy: 0.8401 - 2s/epoch - 2ms/step\n",
            "Epoch 43/200\n",
            "800/800 - 2s - loss: 0.3944 - accuracy: 0.8388 - 2s/epoch - 2ms/step\n",
            "Epoch 44/200\n",
            "800/800 - 2s - loss: 0.3946 - accuracy: 0.8404 - 2s/epoch - 2ms/step\n",
            "Epoch 45/200\n",
            "800/800 - 2s - loss: 0.3944 - accuracy: 0.8393 - 2s/epoch - 2ms/step\n",
            "Epoch 46/200\n",
            "800/800 - 2s - loss: 0.3941 - accuracy: 0.8401 - 2s/epoch - 2ms/step\n",
            "Epoch 47/200\n",
            "800/800 - 2s - loss: 0.3937 - accuracy: 0.8400 - 2s/epoch - 2ms/step\n",
            "Epoch 48/200\n",
            "800/800 - 2s - loss: 0.3943 - accuracy: 0.8397 - 2s/epoch - 2ms/step\n",
            "Epoch 49/200\n",
            "800/800 - 1s - loss: 0.3940 - accuracy: 0.8397 - 1s/epoch - 2ms/step\n",
            "Epoch 50/200\n",
            "800/800 - 1s - loss: 0.3930 - accuracy: 0.8404 - 1s/epoch - 2ms/step\n",
            "Epoch 51/200\n",
            "800/800 - 1s - loss: 0.3939 - accuracy: 0.8395 - 1s/epoch - 1ms/step\n",
            "Epoch 52/200\n",
            "800/800 - 1s - loss: 0.3939 - accuracy: 0.8388 - 1s/epoch - 2ms/step\n",
            "Epoch 53/200\n",
            "800/800 - 2s - loss: 0.3940 - accuracy: 0.8399 - 2s/epoch - 2ms/step\n",
            "Epoch 54/200\n",
            "800/800 - 2s - loss: 0.3940 - accuracy: 0.8407 - 2s/epoch - 2ms/step\n",
            "Epoch 55/200\n",
            "800/800 - 2s - loss: 0.3942 - accuracy: 0.8400 - 2s/epoch - 2ms/step\n",
            "Epoch 56/200\n",
            "800/800 - 1s - loss: 0.3938 - accuracy: 0.8394 - 1s/epoch - 2ms/step\n",
            "Epoch 57/200\n",
            "800/800 - 1s - loss: 0.3935 - accuracy: 0.8395 - 1s/epoch - 1ms/step\n",
            "Epoch 58/200\n",
            "800/800 - 1s - loss: 0.3936 - accuracy: 0.8401 - 1s/epoch - 2ms/step\n",
            "Epoch 59/200\n",
            "800/800 - 1s - loss: 0.3933 - accuracy: 0.8405 - 1s/epoch - 2ms/step\n",
            "Epoch 60/200\n",
            "800/800 - 2s - loss: 0.3933 - accuracy: 0.8391 - 2s/epoch - 2ms/step\n",
            "Epoch 61/200\n",
            "800/800 - 2s - loss: 0.3932 - accuracy: 0.8403 - 2s/epoch - 2ms/step\n",
            "Epoch 62/200\n",
            "800/800 - 1s - loss: 0.3934 - accuracy: 0.8415 - 1s/epoch - 1ms/step\n",
            "Epoch 63/200\n",
            "800/800 - 1s - loss: 0.3935 - accuracy: 0.8395 - 1s/epoch - 2ms/step\n",
            "Epoch 64/200\n",
            "800/800 - 1s - loss: 0.3931 - accuracy: 0.8396 - 1s/epoch - 2ms/step\n",
            "Epoch 65/200\n",
            "800/800 - 1s - loss: 0.3932 - accuracy: 0.8395 - 1s/epoch - 1ms/step\n",
            "Epoch 66/200\n",
            "800/800 - 1s - loss: 0.3928 - accuracy: 0.8407 - 1s/epoch - 2ms/step\n",
            "Epoch 67/200\n",
            "800/800 - 2s - loss: 0.3932 - accuracy: 0.8404 - 2s/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "800/800 - 1s - loss: 0.3928 - accuracy: 0.8403 - 1s/epoch - 2ms/step\n",
            "Epoch 69/200\n",
            "800/800 - 1s - loss: 0.3927 - accuracy: 0.8399 - 1s/epoch - 2ms/step\n",
            "Epoch 70/200\n",
            "800/800 - 1s - loss: 0.3928 - accuracy: 0.8379 - 1s/epoch - 2ms/step\n",
            "Epoch 71/200\n",
            "800/800 - 1s - loss: 0.3929 - accuracy: 0.8382 - 1s/epoch - 2ms/step\n",
            "Epoch 72/200\n",
            "800/800 - 1s - loss: 0.3928 - accuracy: 0.8393 - 1s/epoch - 2ms/step\n",
            "Epoch 73/200\n",
            "800/800 - 2s - loss: 0.3929 - accuracy: 0.8397 - 2s/epoch - 2ms/step\n",
            "Epoch 74/200\n",
            "800/800 - 1s - loss: 0.3929 - accuracy: 0.8394 - 1s/epoch - 2ms/step\n",
            "Epoch 75/200\n",
            "800/800 - 2s - loss: 0.3922 - accuracy: 0.8399 - 2s/epoch - 2ms/step\n",
            "Epoch 76/200\n",
            "800/800 - 1s - loss: 0.3916 - accuracy: 0.8390 - 1s/epoch - 2ms/step\n",
            "Epoch 77/200\n",
            "800/800 - 1s - loss: 0.3905 - accuracy: 0.8378 - 1s/epoch - 2ms/step\n",
            "Epoch 78/200\n",
            "800/800 - 1s - loss: 0.3885 - accuracy: 0.8391 - 1s/epoch - 2ms/step\n",
            "Epoch 79/200\n",
            "800/800 - 1s - loss: 0.3873 - accuracy: 0.8390 - 1s/epoch - 1ms/step\n",
            "Epoch 80/200\n",
            "800/800 - 1s - loss: 0.3834 - accuracy: 0.8401 - 1s/epoch - 2ms/step\n",
            "Epoch 81/200\n",
            "800/800 - 1s - loss: 0.3802 - accuracy: 0.8395 - 1s/epoch - 2ms/step\n",
            "Epoch 82/200\n",
            "800/800 - 1s - loss: 0.3748 - accuracy: 0.8407 - 1s/epoch - 2ms/step\n",
            "Epoch 83/200\n",
            "800/800 - 1s - loss: 0.3696 - accuracy: 0.8456 - 1s/epoch - 2ms/step\n",
            "Epoch 84/200\n",
            "800/800 - 1s - loss: 0.3627 - accuracy: 0.8510 - 1s/epoch - 2ms/step\n",
            "Epoch 85/200\n",
            "800/800 - 2s - loss: 0.3559 - accuracy: 0.8539 - 2s/epoch - 2ms/step\n",
            "Epoch 86/200\n",
            "800/800 - 2s - loss: 0.3511 - accuracy: 0.8564 - 2s/epoch - 2ms/step\n",
            "Epoch 87/200\n",
            "800/800 - 1s - loss: 0.3491 - accuracy: 0.8561 - 1s/epoch - 2ms/step\n",
            "Epoch 88/200\n",
            "800/800 - 1s - loss: 0.3472 - accuracy: 0.8570 - 1s/epoch - 2ms/step\n",
            "Epoch 89/200\n",
            "800/800 - 1s - loss: 0.3459 - accuracy: 0.8559 - 1s/epoch - 2ms/step\n",
            "Epoch 90/200\n",
            "800/800 - 2s - loss: 0.3444 - accuracy: 0.8585 - 2s/epoch - 2ms/step\n",
            "Epoch 91/200\n",
            "800/800 - 2s - loss: 0.3439 - accuracy: 0.8566 - 2s/epoch - 2ms/step\n",
            "Epoch 92/200\n",
            "800/800 - 1s - loss: 0.3439 - accuracy: 0.8602 - 1s/epoch - 2ms/step\n",
            "Epoch 93/200\n",
            "800/800 - 1s - loss: 0.3433 - accuracy: 0.8574 - 1s/epoch - 2ms/step\n",
            "Epoch 94/200\n",
            "800/800 - 2s - loss: 0.3436 - accuracy: 0.8583 - 2s/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "800/800 - 3s - loss: 0.3432 - accuracy: 0.8579 - 3s/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "800/800 - 4s - loss: 0.3425 - accuracy: 0.8595 - 4s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "800/800 - 3s - loss: 0.3424 - accuracy: 0.8606 - 3s/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "800/800 - 2s - loss: 0.3416 - accuracy: 0.8581 - 2s/epoch - 2ms/step\n",
            "Epoch 99/200\n",
            "800/800 - 1s - loss: 0.3421 - accuracy: 0.8581 - 1s/epoch - 2ms/step\n",
            "Epoch 100/200\n",
            "800/800 - 1s - loss: 0.3414 - accuracy: 0.8587 - 1s/epoch - 2ms/step\n",
            "Epoch 101/200\n",
            "800/800 - 1s - loss: 0.3409 - accuracy: 0.8602 - 1s/epoch - 2ms/step\n",
            "Epoch 102/200\n",
            "800/800 - 2s - loss: 0.3410 - accuracy: 0.8599 - 2s/epoch - 2ms/step\n",
            "Epoch 103/200\n",
            "800/800 - 1s - loss: 0.3409 - accuracy: 0.8597 - 1s/epoch - 2ms/step\n",
            "Epoch 104/200\n",
            "800/800 - 1s - loss: 0.3414 - accuracy: 0.8583 - 1s/epoch - 2ms/step\n",
            "Epoch 105/200\n",
            "800/800 - 1s - loss: 0.3404 - accuracy: 0.8611 - 1s/epoch - 2ms/step\n",
            "Epoch 106/200\n",
            "800/800 - 1s - loss: 0.3406 - accuracy: 0.8590 - 1s/epoch - 2ms/step\n",
            "Epoch 107/200\n",
            "800/800 - 2s - loss: 0.3400 - accuracy: 0.8612 - 2s/epoch - 2ms/step\n",
            "Epoch 108/200\n",
            "800/800 - 1s - loss: 0.3401 - accuracy: 0.8616 - 1s/epoch - 2ms/step\n",
            "Epoch 109/200\n",
            "800/800 - 1s - loss: 0.3394 - accuracy: 0.8619 - 1s/epoch - 2ms/step\n",
            "Epoch 110/200\n",
            "800/800 - 1s - loss: 0.3401 - accuracy: 0.8606 - 1s/epoch - 2ms/step\n",
            "Epoch 111/200\n",
            "800/800 - 2s - loss: 0.3404 - accuracy: 0.8608 - 2s/epoch - 2ms/step\n",
            "Epoch 112/200\n",
            "800/800 - 1s - loss: 0.3404 - accuracy: 0.8602 - 1s/epoch - 2ms/step\n",
            "Epoch 113/200\n",
            "800/800 - 2s - loss: 0.3401 - accuracy: 0.8609 - 2s/epoch - 2ms/step\n",
            "Epoch 114/200\n",
            "800/800 - 1s - loss: 0.3397 - accuracy: 0.8610 - 1s/epoch - 2ms/step\n",
            "Epoch 115/200\n",
            "800/800 - 1s - loss: 0.3398 - accuracy: 0.8600 - 1s/epoch - 2ms/step\n",
            "Epoch 116/200\n",
            "800/800 - 1s - loss: 0.3399 - accuracy: 0.8589 - 1s/epoch - 2ms/step\n",
            "Epoch 117/200\n",
            "800/800 - 2s - loss: 0.3400 - accuracy: 0.8618 - 2s/epoch - 2ms/step\n",
            "Epoch 118/200\n",
            "800/800 - 2s - loss: 0.3402 - accuracy: 0.8614 - 2s/epoch - 3ms/step\n",
            "Epoch 119/200\n",
            "800/800 - 1s - loss: 0.3387 - accuracy: 0.8615 - 1s/epoch - 2ms/step\n",
            "Epoch 120/200\n",
            "800/800 - 1s - loss: 0.3397 - accuracy: 0.8589 - 1s/epoch - 2ms/step\n",
            "Epoch 121/200\n",
            "800/800 - 1s - loss: 0.3393 - accuracy: 0.8629 - 1s/epoch - 2ms/step\n",
            "Epoch 122/200\n",
            "800/800 - 2s - loss: 0.3396 - accuracy: 0.8610 - 2s/epoch - 2ms/step\n",
            "Epoch 123/200\n",
            "800/800 - 2s - loss: 0.3396 - accuracy: 0.8593 - 2s/epoch - 2ms/step\n",
            "Epoch 124/200\n",
            "800/800 - 1s - loss: 0.3391 - accuracy: 0.8593 - 938ms/epoch - 1ms/step\n",
            "Epoch 125/200\n",
            "800/800 - 1s - loss: 0.3391 - accuracy: 0.8605 - 956ms/epoch - 1ms/step\n",
            "Epoch 126/200\n",
            "800/800 - 1s - loss: 0.3391 - accuracy: 0.8600 - 1s/epoch - 1ms/step\n",
            "Epoch 127/200\n",
            "800/800 - 2s - loss: 0.3385 - accuracy: 0.8627 - 2s/epoch - 2ms/step\n",
            "Epoch 128/200\n",
            "800/800 - 2s - loss: 0.3388 - accuracy: 0.8600 - 2s/epoch - 2ms/step\n",
            "Epoch 129/200\n",
            "800/800 - 3s - loss: 0.3389 - accuracy: 0.8606 - 3s/epoch - 3ms/step\n",
            "Epoch 130/200\n",
            "800/800 - 2s - loss: 0.3384 - accuracy: 0.8609 - 2s/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "800/800 - 2s - loss: 0.3380 - accuracy: 0.8624 - 2s/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "800/800 - 1s - loss: 0.3382 - accuracy: 0.8608 - 1s/epoch - 2ms/step\n",
            "Epoch 133/200\n",
            "800/800 - 1s - loss: 0.3380 - accuracy: 0.8612 - 1s/epoch - 2ms/step\n",
            "Epoch 134/200\n",
            "800/800 - 1s - loss: 0.3383 - accuracy: 0.8612 - 1s/epoch - 2ms/step\n",
            "Epoch 135/200\n",
            "800/800 - 2s - loss: 0.3381 - accuracy: 0.8625 - 2s/epoch - 3ms/step\n",
            "Epoch 136/200\n",
            "800/800 - 2s - loss: 0.3380 - accuracy: 0.8601 - 2s/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "800/800 - 2s - loss: 0.3378 - accuracy: 0.8599 - 2s/epoch - 2ms/step\n",
            "Epoch 138/200\n",
            "800/800 - 1s - loss: 0.3375 - accuracy: 0.8602 - 1s/epoch - 2ms/step\n",
            "Epoch 139/200\n",
            "800/800 - 1s - loss: 0.3369 - accuracy: 0.8611 - 1s/epoch - 1ms/step\n",
            "Epoch 140/200\n",
            "800/800 - 1s - loss: 0.3380 - accuracy: 0.8599 - 1s/epoch - 2ms/step\n",
            "Epoch 141/200\n",
            "800/800 - 1s - loss: 0.3375 - accuracy: 0.8625 - 1s/epoch - 2ms/step\n",
            "Epoch 142/200\n",
            "800/800 - 2s - loss: 0.3371 - accuracy: 0.8616 - 2s/epoch - 2ms/step\n",
            "Epoch 143/200\n",
            "800/800 - 2s - loss: 0.3372 - accuracy: 0.8604 - 2s/epoch - 2ms/step\n",
            "Epoch 144/200\n",
            "800/800 - 2s - loss: 0.3367 - accuracy: 0.8604 - 2s/epoch - 2ms/step\n",
            "Epoch 145/200\n",
            "800/800 - 1s - loss: 0.3377 - accuracy: 0.8600 - 1s/epoch - 1ms/step\n",
            "Epoch 146/200\n",
            "800/800 - 1s - loss: 0.3367 - accuracy: 0.8609 - 1s/epoch - 1ms/step\n",
            "Epoch 147/200\n",
            "800/800 - 1s - loss: 0.3370 - accuracy: 0.8601 - 1s/epoch - 1ms/step\n",
            "Epoch 148/200\n",
            "800/800 - 1s - loss: 0.3371 - accuracy: 0.8594 - 1s/epoch - 1ms/step\n",
            "Epoch 149/200\n",
            "800/800 - 1s - loss: 0.3366 - accuracy: 0.8594 - 1s/epoch - 2ms/step\n",
            "Epoch 150/200\n",
            "800/800 - 1s - loss: 0.3364 - accuracy: 0.8616 - 1s/epoch - 2ms/step\n",
            "Epoch 151/200\n",
            "800/800 - 2s - loss: 0.3362 - accuracy: 0.8601 - 2s/epoch - 2ms/step\n",
            "Epoch 152/200\n",
            "800/800 - 2s - loss: 0.3363 - accuracy: 0.8586 - 2s/epoch - 2ms/step\n",
            "Epoch 153/200\n",
            "800/800 - 2s - loss: 0.3364 - accuracy: 0.8599 - 2s/epoch - 2ms/step\n",
            "Epoch 154/200\n",
            "800/800 - 2s - loss: 0.3361 - accuracy: 0.8609 - 2s/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "800/800 - 2s - loss: 0.3373 - accuracy: 0.8596 - 2s/epoch - 2ms/step\n",
            "Epoch 156/200\n",
            "800/800 - 1s - loss: 0.3358 - accuracy: 0.8609 - 1s/epoch - 2ms/step\n",
            "Epoch 157/200\n",
            "800/800 - 2s - loss: 0.3364 - accuracy: 0.8615 - 2s/epoch - 2ms/step\n",
            "Epoch 158/200\n",
            "800/800 - 2s - loss: 0.3361 - accuracy: 0.8599 - 2s/epoch - 3ms/step\n",
            "Epoch 159/200\n",
            "800/800 - 2s - loss: 0.3365 - accuracy: 0.8616 - 2s/epoch - 3ms/step\n",
            "Epoch 160/200\n",
            "800/800 - 2s - loss: 0.3362 - accuracy: 0.8597 - 2s/epoch - 2ms/step\n",
            "Epoch 161/200\n",
            "800/800 - 2s - loss: 0.3362 - accuracy: 0.8611 - 2s/epoch - 2ms/step\n",
            "Epoch 162/200\n",
            "800/800 - 2s - loss: 0.3359 - accuracy: 0.8593 - 2s/epoch - 2ms/step\n",
            "Epoch 163/200\n",
            "800/800 - 1s - loss: 0.3365 - accuracy: 0.8608 - 1s/epoch - 2ms/step\n",
            "Epoch 164/200\n",
            "800/800 - 2s - loss: 0.3360 - accuracy: 0.8612 - 2s/epoch - 2ms/step\n",
            "Epoch 165/200\n",
            "800/800 - 2s - loss: 0.3360 - accuracy: 0.8606 - 2s/epoch - 2ms/step\n",
            "Epoch 166/200\n",
            "800/800 - 2s - loss: 0.3361 - accuracy: 0.8612 - 2s/epoch - 2ms/step\n",
            "Epoch 167/200\n",
            "800/800 - 1s - loss: 0.3359 - accuracy: 0.8611 - 1s/epoch - 2ms/step\n",
            "Epoch 168/200\n",
            "800/800 - 1s - loss: 0.3363 - accuracy: 0.8596 - 1s/epoch - 2ms/step\n",
            "Epoch 169/200\n",
            "800/800 - 1s - loss: 0.3352 - accuracy: 0.8596 - 1s/epoch - 2ms/step\n",
            "Epoch 170/200\n",
            "800/800 - 2s - loss: 0.3358 - accuracy: 0.8606 - 2s/epoch - 3ms/step\n",
            "Epoch 171/200\n",
            "800/800 - 1s - loss: 0.3359 - accuracy: 0.8609 - 1s/epoch - 2ms/step\n",
            "Epoch 172/200\n",
            "800/800 - 1s - loss: 0.3361 - accuracy: 0.8597 - 1s/epoch - 2ms/step\n",
            "Epoch 173/200\n",
            "800/800 - 2s - loss: 0.3359 - accuracy: 0.8611 - 2s/epoch - 2ms/step\n",
            "Epoch 174/200\n",
            "800/800 - 2s - loss: 0.3358 - accuracy: 0.8591 - 2s/epoch - 2ms/step\n",
            "Epoch 175/200\n",
            "800/800 - 1s - loss: 0.3351 - accuracy: 0.8618 - 1s/epoch - 2ms/step\n",
            "Epoch 176/200\n",
            "800/800 - 1s - loss: 0.3358 - accuracy: 0.8610 - 1s/epoch - 2ms/step\n",
            "Epoch 177/200\n",
            "800/800 - 2s - loss: 0.3354 - accuracy: 0.8605 - 2s/epoch - 2ms/step\n",
            "Epoch 178/200\n",
            "800/800 - 2s - loss: 0.3360 - accuracy: 0.8624 - 2s/epoch - 2ms/step\n",
            "Epoch 179/200\n",
            "800/800 - 2s - loss: 0.3357 - accuracy: 0.8597 - 2s/epoch - 2ms/step\n",
            "Epoch 180/200\n",
            "800/800 - 1s - loss: 0.3361 - accuracy: 0.8599 - 1s/epoch - 2ms/step\n",
            "Epoch 181/200\n",
            "800/800 - 1s - loss: 0.3356 - accuracy: 0.8591 - 1s/epoch - 2ms/step\n",
            "Epoch 182/200\n",
            "800/800 - 2s - loss: 0.3359 - accuracy: 0.8614 - 2s/epoch - 2ms/step\n",
            "Epoch 183/200\n",
            "800/800 - 1s - loss: 0.3352 - accuracy: 0.8596 - 1s/epoch - 2ms/step\n",
            "Epoch 184/200\n",
            "800/800 - 1s - loss: 0.3354 - accuracy: 0.8609 - 1s/epoch - 2ms/step\n",
            "Epoch 185/200\n",
            "800/800 - 1s - loss: 0.3353 - accuracy: 0.8604 - 1s/epoch - 2ms/step\n",
            "Epoch 186/200\n",
            "800/800 - 2s - loss: 0.3355 - accuracy: 0.8627 - 2s/epoch - 2ms/step\n",
            "Epoch 187/200\n",
            "800/800 - 2s - loss: 0.3359 - accuracy: 0.8611 - 2s/epoch - 2ms/step\n",
            "Epoch 188/200\n",
            "800/800 - 2s - loss: 0.3351 - accuracy: 0.8602 - 2s/epoch - 2ms/step\n",
            "Epoch 189/200\n",
            "800/800 - 2s - loss: 0.3358 - accuracy: 0.8589 - 2s/epoch - 2ms/step\n",
            "Epoch 190/200\n",
            "800/800 - 2s - loss: 0.3356 - accuracy: 0.8612 - 2s/epoch - 2ms/step\n",
            "Epoch 191/200\n",
            "800/800 - 2s - loss: 0.3357 - accuracy: 0.8601 - 2s/epoch - 2ms/step\n",
            "Epoch 192/200\n",
            "800/800 - 2s - loss: 0.3353 - accuracy: 0.8605 - 2s/epoch - 2ms/step\n",
            "Epoch 193/200\n",
            "800/800 - 1s - loss: 0.3352 - accuracy: 0.8595 - 1s/epoch - 2ms/step\n",
            "Epoch 194/200\n",
            "800/800 - 2s - loss: 0.3348 - accuracy: 0.8610 - 2s/epoch - 2ms/step\n",
            "Epoch 195/200\n",
            "800/800 - 1s - loss: 0.3356 - accuracy: 0.8604 - 1s/epoch - 2ms/step\n",
            "Epoch 196/200\n",
            "800/800 - 2s - loss: 0.3350 - accuracy: 0.8595 - 2s/epoch - 2ms/step\n",
            "Epoch 197/200\n",
            "800/800 - 1s - loss: 0.3352 - accuracy: 0.8605 - 1s/epoch - 2ms/step\n",
            "Epoch 198/200\n",
            "800/800 - 2s - loss: 0.3350 - accuracy: 0.8635 - 2s/epoch - 2ms/step\n",
            "Epoch 199/200\n",
            "800/800 - 1s - loss: 0.3357 - accuracy: 0.8610 - 1s/epoch - 2ms/step\n",
            "Epoch 200/200\n",
            "800/800 - 1s - loss: 0.3352 - accuracy: 0.8602 - 1s/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show details\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugmKIK2daJT6",
        "outputId": "1fcd23f2-f202-44ab-937e-07d9a6c8a24c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (10, 6)                   72        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (10, 6)                   42        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (10, 1)                   7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model_loss, model_acc = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL5i0GF7aYAg",
        "outputId": "d32d2109-6edd-4066-a047-5ee6cc786283"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNObC1QatmT",
        "outputId": "7028aeee-fa55-4572-d549-5ee137ccbe3f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3290959298610687"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcVpxeLaw3X",
        "outputId": "541fa8d8-19d8-4eef-d38e-3c501ec5a0c5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8619999885559082"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference: predict now \n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4kdrPMQjNOL",
        "outputId": "931c1125-abe2-44e8-97cb-84c370d15626"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert y_pred to 0-1 values using astype() method\n",
        "y_pred = y_pred.astype(int) \n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vToTblxUbGU_",
        "outputId": "1951117b-897b-43ce-aeb3-61d11c60b33c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicti using the info of new customer\n",
        "new_customer = [[0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]\n",
        "new_customer = sc.fit_transform(new_customer)\n",
        "new_pred = model.predict(new_customer)\n",
        "new_pred = (new_pred > 0.5)\n",
        "print(new_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mZMAcvnjg_B",
        "outputId": "f6bad3c3-4fad-42d8-8ed6-509fa54a07e2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuray')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['accuracy', 'epochs'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7IU5uolkjhCS",
        "outputId": "62309b03-7503-4640-c93d-82f03d5bbfff"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An alternative to using train_test_split is to specify a validation_split ration\n",
        "from traitlets.traitlets import validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Standardize\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "# train\n",
        "history = model.fit(X, y,                   # X_standardize direct here\n",
        "                    verbose=1,\n",
        "                    validation_split = 0.2, # split at 80% - 20%\n",
        "                    epochs=200,\n",
        "                    batch_size=10\n",
        "                   )\n",
        "#Note: do not perform better than the first method of splitting !"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reDEy3dCjhGT",
        "outputId": "d8283fcf-4a35-41f9-e5ec-e41001b2c83e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3315 - accuracy: 0.8624 - val_loss: 0.3431 - val_accuracy: 0.8605\n",
            "Epoch 2/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3312 - accuracy: 0.8627 - val_loss: 0.3447 - val_accuracy: 0.8575\n",
            "Epoch 3/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3314 - accuracy: 0.8611 - val_loss: 0.3453 - val_accuracy: 0.8605\n",
            "Epoch 4/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3313 - accuracy: 0.8631 - val_loss: 0.3458 - val_accuracy: 0.8580\n",
            "Epoch 5/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8633 - val_loss: 0.3441 - val_accuracy: 0.8600\n",
            "Epoch 6/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3307 - accuracy: 0.8622 - val_loss: 0.3491 - val_accuracy: 0.8570\n",
            "Epoch 7/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3316 - accuracy: 0.8595 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
            "Epoch 8/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3310 - accuracy: 0.8612 - val_loss: 0.3454 - val_accuracy: 0.8605\n",
            "Epoch 9/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3308 - accuracy: 0.8593 - val_loss: 0.3456 - val_accuracy: 0.8610\n",
            "Epoch 10/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3310 - accuracy: 0.8622 - val_loss: 0.3442 - val_accuracy: 0.8615\n",
            "Epoch 11/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8618 - val_loss: 0.3447 - val_accuracy: 0.8600\n",
            "Epoch 12/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3307 - accuracy: 0.8643 - val_loss: 0.3443 - val_accuracy: 0.8590\n",
            "Epoch 13/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3307 - accuracy: 0.8626 - val_loss: 0.3444 - val_accuracy: 0.8600\n",
            "Epoch 14/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8624 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
            "Epoch 15/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3305 - accuracy: 0.8609 - val_loss: 0.3454 - val_accuracy: 0.8570\n",
            "Epoch 16/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8610 - val_loss: 0.3451 - val_accuracy: 0.8605\n",
            "Epoch 17/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8626 - val_loss: 0.3454 - val_accuracy: 0.8585\n",
            "Epoch 18/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8610 - val_loss: 0.3456 - val_accuracy: 0.8580\n",
            "Epoch 19/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8620 - val_loss: 0.3447 - val_accuracy: 0.8595\n",
            "Epoch 20/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8608 - val_loss: 0.3449 - val_accuracy: 0.8590\n",
            "Epoch 21/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8629 - val_loss: 0.3457 - val_accuracy: 0.8575\n",
            "Epoch 22/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8600 - val_loss: 0.3456 - val_accuracy: 0.8615\n",
            "Epoch 23/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3305 - accuracy: 0.8641 - val_loss: 0.3474 - val_accuracy: 0.8605\n",
            "Epoch 24/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3304 - accuracy: 0.8627 - val_loss: 0.3448 - val_accuracy: 0.8570\n",
            "Epoch 25/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3309 - accuracy: 0.8619 - val_loss: 0.3444 - val_accuracy: 0.8590\n",
            "Epoch 26/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3303 - accuracy: 0.8621 - val_loss: 0.3452 - val_accuracy: 0.8590\n",
            "Epoch 27/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3307 - accuracy: 0.8626 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
            "Epoch 28/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3302 - accuracy: 0.8631 - val_loss: 0.3476 - val_accuracy: 0.8585\n",
            "Epoch 29/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3300 - accuracy: 0.8629 - val_loss: 0.3448 - val_accuracy: 0.8625\n",
            "Epoch 30/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3301 - accuracy: 0.8620 - val_loss: 0.3477 - val_accuracy: 0.8600\n",
            "Epoch 31/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3299 - accuracy: 0.8634 - val_loss: 0.3473 - val_accuracy: 0.8575\n",
            "Epoch 32/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3306 - accuracy: 0.8619 - val_loss: 0.3461 - val_accuracy: 0.8555\n",
            "Epoch 33/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3300 - accuracy: 0.8629 - val_loss: 0.3448 - val_accuracy: 0.8590\n",
            "Epoch 34/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3295 - accuracy: 0.8633 - val_loss: 0.3450 - val_accuracy: 0.8570\n",
            "Epoch 35/200\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.3305 - accuracy: 0.8620 - val_loss: 0.3461 - val_accuracy: 0.8600\n",
            "Epoch 36/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3303 - accuracy: 0.8635 - val_loss: 0.3459 - val_accuracy: 0.8595\n",
            "Epoch 37/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3300 - accuracy: 0.8622 - val_loss: 0.3495 - val_accuracy: 0.8535\n",
            "Epoch 38/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3299 - accuracy: 0.8634 - val_loss: 0.3460 - val_accuracy: 0.8595\n",
            "Epoch 39/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3302 - accuracy: 0.8620 - val_loss: 0.3473 - val_accuracy: 0.8580\n",
            "Epoch 40/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3301 - accuracy: 0.8626 - val_loss: 0.3460 - val_accuracy: 0.8595\n",
            "Epoch 41/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3302 - accuracy: 0.8626 - val_loss: 0.3458 - val_accuracy: 0.8595\n",
            "Epoch 42/200\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3300 - accuracy: 0.8625 - val_loss: 0.3463 - val_accuracy: 0.8575\n",
            "Epoch 43/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3302 - accuracy: 0.8627 - val_loss: 0.3446 - val_accuracy: 0.8585\n",
            "Epoch 44/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3293 - accuracy: 0.8641 - val_loss: 0.3467 - val_accuracy: 0.8595\n",
            "Epoch 45/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3301 - accuracy: 0.8624 - val_loss: 0.3455 - val_accuracy: 0.8595\n",
            "Epoch 46/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3300 - accuracy: 0.8629 - val_loss: 0.3474 - val_accuracy: 0.8635\n",
            "Epoch 47/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3298 - accuracy: 0.8615 - val_loss: 0.3481 - val_accuracy: 0.8620\n",
            "Epoch 48/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3301 - accuracy: 0.8624 - val_loss: 0.3475 - val_accuracy: 0.8590\n",
            "Epoch 49/200\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3298 - accuracy: 0.8615 - val_loss: 0.3465 - val_accuracy: 0.8575\n",
            "Epoch 50/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8646 - val_loss: 0.3489 - val_accuracy: 0.8630\n",
            "Epoch 51/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8634 - val_loss: 0.3488 - val_accuracy: 0.8545\n",
            "Epoch 52/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3301 - accuracy: 0.8627 - val_loss: 0.3456 - val_accuracy: 0.8610\n",
            "Epoch 53/200\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.3301 - accuracy: 0.8611 - val_loss: 0.3470 - val_accuracy: 0.8580\n",
            "Epoch 54/200\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.3292 - accuracy: 0.8648 - val_loss: 0.3471 - val_accuracy: 0.8595\n",
            "Epoch 55/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3305 - accuracy: 0.8621 - val_loss: 0.3476 - val_accuracy: 0.8600\n",
            "Epoch 56/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8614 - val_loss: 0.3456 - val_accuracy: 0.8580\n",
            "Epoch 57/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3305 - accuracy: 0.8624 - val_loss: 0.3475 - val_accuracy: 0.8580\n",
            "Epoch 58/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3288 - accuracy: 0.8637 - val_loss: 0.3469 - val_accuracy: 0.8590\n",
            "Epoch 59/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3300 - accuracy: 0.8625 - val_loss: 0.3472 - val_accuracy: 0.8585\n",
            "Epoch 60/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8651 - val_loss: 0.3474 - val_accuracy: 0.8575\n",
            "Epoch 61/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3299 - accuracy: 0.8611 - val_loss: 0.3509 - val_accuracy: 0.8595\n",
            "Epoch 62/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3302 - accuracy: 0.8649 - val_loss: 0.3478 - val_accuracy: 0.8565\n",
            "Epoch 63/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3295 - accuracy: 0.8634 - val_loss: 0.3486 - val_accuracy: 0.8555\n",
            "Epoch 64/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3296 - accuracy: 0.8637 - val_loss: 0.3461 - val_accuracy: 0.8590\n",
            "Epoch 65/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3297 - accuracy: 0.8640 - val_loss: 0.3461 - val_accuracy: 0.8610\n",
            "Epoch 66/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3306 - accuracy: 0.8621 - val_loss: 0.3467 - val_accuracy: 0.8585\n",
            "Epoch 67/200\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3300 - accuracy: 0.8619 - val_loss: 0.3453 - val_accuracy: 0.8585\n",
            "Epoch 68/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8624 - val_loss: 0.3490 - val_accuracy: 0.8580\n",
            "Epoch 69/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8627 - val_loss: 0.3473 - val_accuracy: 0.8560\n",
            "Epoch 70/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3294 - accuracy: 0.8625 - val_loss: 0.3455 - val_accuracy: 0.8585\n",
            "Epoch 71/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3301 - accuracy: 0.8619 - val_loss: 0.3457 - val_accuracy: 0.8585\n",
            "Epoch 72/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8626 - val_loss: 0.3473 - val_accuracy: 0.8585\n",
            "Epoch 73/200\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.3296 - accuracy: 0.8629 - val_loss: 0.3459 - val_accuracy: 0.8600\n",
            "Epoch 74/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3293 - accuracy: 0.8624 - val_loss: 0.3494 - val_accuracy: 0.8555\n",
            "Epoch 75/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8640 - val_loss: 0.3480 - val_accuracy: 0.8570\n",
            "Epoch 76/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3302 - accuracy: 0.8633 - val_loss: 0.3477 - val_accuracy: 0.8570\n",
            "Epoch 77/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3297 - accuracy: 0.8618 - val_loss: 0.3496 - val_accuracy: 0.8580\n",
            "Epoch 78/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3292 - accuracy: 0.8625 - val_loss: 0.3471 - val_accuracy: 0.8585\n",
            "Epoch 79/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8627 - val_loss: 0.3480 - val_accuracy: 0.8575\n",
            "Epoch 80/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8625 - val_loss: 0.3448 - val_accuracy: 0.8580\n",
            "Epoch 81/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8629 - val_loss: 0.3466 - val_accuracy: 0.8585\n",
            "Epoch 82/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3297 - accuracy: 0.8627 - val_loss: 0.3474 - val_accuracy: 0.8575\n",
            "Epoch 83/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3292 - accuracy: 0.8626 - val_loss: 0.3479 - val_accuracy: 0.8565\n",
            "Epoch 84/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8633 - val_loss: 0.3521 - val_accuracy: 0.8605\n",
            "Epoch 85/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3296 - accuracy: 0.8630 - val_loss: 0.3453 - val_accuracy: 0.8565\n",
            "Epoch 86/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3293 - accuracy: 0.8646 - val_loss: 0.3501 - val_accuracy: 0.8535\n",
            "Epoch 87/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8620 - val_loss: 0.3510 - val_accuracy: 0.8595\n",
            "Epoch 88/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3289 - accuracy: 0.8635 - val_loss: 0.3460 - val_accuracy: 0.8535\n",
            "Epoch 89/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3295 - accuracy: 0.8635 - val_loss: 0.3522 - val_accuracy: 0.8575\n",
            "Epoch 90/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8621 - val_loss: 0.3480 - val_accuracy: 0.8555\n",
            "Epoch 91/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3294 - accuracy: 0.8634 - val_loss: 0.3504 - val_accuracy: 0.8555\n",
            "Epoch 92/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3294 - accuracy: 0.8626 - val_loss: 0.3484 - val_accuracy: 0.8615\n",
            "Epoch 93/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8615 - val_loss: 0.3475 - val_accuracy: 0.8595\n",
            "Epoch 94/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8616 - val_loss: 0.3451 - val_accuracy: 0.8555\n",
            "Epoch 95/200\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.3299 - accuracy: 0.8643 - val_loss: 0.3456 - val_accuracy: 0.8590\n",
            "Epoch 96/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3294 - accuracy: 0.8639 - val_loss: 0.3467 - val_accuracy: 0.8550\n",
            "Epoch 97/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8646 - val_loss: 0.3458 - val_accuracy: 0.8575\n",
            "Epoch 98/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8633 - val_loss: 0.3483 - val_accuracy: 0.8550\n",
            "Epoch 99/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3293 - accuracy: 0.8616 - val_loss: 0.3513 - val_accuracy: 0.8575\n",
            "Epoch 100/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3295 - accuracy: 0.8630 - val_loss: 0.3479 - val_accuracy: 0.8540\n",
            "Epoch 101/200\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3294 - accuracy: 0.8650 - val_loss: 0.3474 - val_accuracy: 0.8575\n",
            "Epoch 102/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3295 - accuracy: 0.8639 - val_loss: 0.3502 - val_accuracy: 0.8590\n",
            "Epoch 103/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8644 - val_loss: 0.3463 - val_accuracy: 0.8560\n",
            "Epoch 104/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3300 - accuracy: 0.8635 - val_loss: 0.3461 - val_accuracy: 0.8570\n",
            "Epoch 105/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3294 - accuracy: 0.8633 - val_loss: 0.3460 - val_accuracy: 0.8545\n",
            "Epoch 106/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3291 - accuracy: 0.8619 - val_loss: 0.3462 - val_accuracy: 0.8545\n",
            "Epoch 107/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8636 - val_loss: 0.3480 - val_accuracy: 0.8565\n",
            "Epoch 108/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3296 - accuracy: 0.8643 - val_loss: 0.3468 - val_accuracy: 0.8540\n",
            "Epoch 109/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8633 - val_loss: 0.3497 - val_accuracy: 0.8565\n",
            "Epoch 110/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3296 - accuracy: 0.8646 - val_loss: 0.3497 - val_accuracy: 0.8605\n",
            "Epoch 111/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8635 - val_loss: 0.3475 - val_accuracy: 0.8570\n",
            "Epoch 112/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8643 - val_loss: 0.3451 - val_accuracy: 0.8555\n",
            "Epoch 113/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8627 - val_loss: 0.3461 - val_accuracy: 0.8545\n",
            "Epoch 114/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8620 - val_loss: 0.3486 - val_accuracy: 0.8575\n",
            "Epoch 115/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3285 - accuracy: 0.8646 - val_loss: 0.3474 - val_accuracy: 0.8555\n",
            "Epoch 116/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8631 - val_loss: 0.3483 - val_accuracy: 0.8580\n",
            "Epoch 117/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8627 - val_loss: 0.3472 - val_accuracy: 0.8585\n",
            "Epoch 118/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3296 - accuracy: 0.8634 - val_loss: 0.3471 - val_accuracy: 0.8590\n",
            "Epoch 119/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8637 - val_loss: 0.3484 - val_accuracy: 0.8560\n",
            "Epoch 120/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3300 - accuracy: 0.8622 - val_loss: 0.3462 - val_accuracy: 0.8565\n",
            "Epoch 121/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3287 - accuracy: 0.8627 - val_loss: 0.3485 - val_accuracy: 0.8560\n",
            "Epoch 122/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8630 - val_loss: 0.3479 - val_accuracy: 0.8575\n",
            "Epoch 123/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8634 - val_loss: 0.3461 - val_accuracy: 0.8570\n",
            "Epoch 124/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8635 - val_loss: 0.3463 - val_accuracy: 0.8545\n",
            "Epoch 125/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3287 - accuracy: 0.8627 - val_loss: 0.3525 - val_accuracy: 0.8585\n",
            "Epoch 126/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8635 - val_loss: 0.3457 - val_accuracy: 0.8555\n",
            "Epoch 127/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3297 - accuracy: 0.8620 - val_loss: 0.3495 - val_accuracy: 0.8570\n",
            "Epoch 128/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3290 - accuracy: 0.8648 - val_loss: 0.3464 - val_accuracy: 0.8555\n",
            "Epoch 129/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8620 - val_loss: 0.3506 - val_accuracy: 0.8580\n",
            "Epoch 130/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8629 - val_loss: 0.3475 - val_accuracy: 0.8565\n",
            "Epoch 131/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8643 - val_loss: 0.3469 - val_accuracy: 0.8570\n",
            "Epoch 132/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8634 - val_loss: 0.3510 - val_accuracy: 0.8610\n",
            "Epoch 133/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8641 - val_loss: 0.3469 - val_accuracy: 0.8580\n",
            "Epoch 134/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8640 - val_loss: 0.3479 - val_accuracy: 0.8555\n",
            "Epoch 135/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3295 - accuracy: 0.8620 - val_loss: 0.3485 - val_accuracy: 0.8570\n",
            "Epoch 136/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8641 - val_loss: 0.3489 - val_accuracy: 0.8555\n",
            "Epoch 137/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8640 - val_loss: 0.3461 - val_accuracy: 0.8580\n",
            "Epoch 138/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8634 - val_loss: 0.3482 - val_accuracy: 0.8555\n",
            "Epoch 139/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3288 - accuracy: 0.8662 - val_loss: 0.3469 - val_accuracy: 0.8565\n",
            "Epoch 140/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3288 - accuracy: 0.8649 - val_loss: 0.3505 - val_accuracy: 0.8550\n",
            "Epoch 141/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8649 - val_loss: 0.3475 - val_accuracy: 0.8550\n",
            "Epoch 142/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8639 - val_loss: 0.3459 - val_accuracy: 0.8590\n",
            "Epoch 143/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8641 - val_loss: 0.3471 - val_accuracy: 0.8575\n",
            "Epoch 144/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8648 - val_loss: 0.3460 - val_accuracy: 0.8580\n",
            "Epoch 145/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8643 - val_loss: 0.3480 - val_accuracy: 0.8585\n",
            "Epoch 146/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8626 - val_loss: 0.3462 - val_accuracy: 0.8560\n",
            "Epoch 147/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8640 - val_loss: 0.3478 - val_accuracy: 0.8550\n",
            "Epoch 148/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8646 - val_loss: 0.3468 - val_accuracy: 0.8575\n",
            "Epoch 149/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3287 - accuracy: 0.8643 - val_loss: 0.3455 - val_accuracy: 0.8555\n",
            "Epoch 150/200\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3286 - accuracy: 0.8633 - val_loss: 0.3511 - val_accuracy: 0.8570\n",
            "Epoch 151/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8649 - val_loss: 0.3479 - val_accuracy: 0.8545\n",
            "Epoch 152/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8644 - val_loss: 0.3480 - val_accuracy: 0.8595\n",
            "Epoch 153/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3290 - accuracy: 0.8626 - val_loss: 0.3486 - val_accuracy: 0.8575\n",
            "Epoch 154/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8637 - val_loss: 0.3495 - val_accuracy: 0.8570\n",
            "Epoch 155/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8639 - val_loss: 0.3461 - val_accuracy: 0.8545\n",
            "Epoch 156/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8622 - val_loss: 0.3486 - val_accuracy: 0.8550\n",
            "Epoch 157/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8625 - val_loss: 0.3522 - val_accuracy: 0.8560\n",
            "Epoch 158/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8655 - val_loss: 0.3489 - val_accuracy: 0.8580\n",
            "Epoch 159/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8650 - val_loss: 0.3471 - val_accuracy: 0.8530\n",
            "Epoch 160/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8626 - val_loss: 0.3481 - val_accuracy: 0.8555\n",
            "Epoch 161/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8631 - val_loss: 0.3486 - val_accuracy: 0.8540\n",
            "Epoch 162/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8645 - val_loss: 0.3476 - val_accuracy: 0.8550\n",
            "Epoch 163/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8627 - val_loss: 0.3494 - val_accuracy: 0.8565\n",
            "Epoch 164/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8655 - val_loss: 0.3482 - val_accuracy: 0.8575\n",
            "Epoch 165/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8622 - val_loss: 0.3485 - val_accuracy: 0.8565\n",
            "Epoch 166/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8618 - val_loss: 0.3483 - val_accuracy: 0.8595\n",
            "Epoch 167/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3287 - accuracy: 0.8644 - val_loss: 0.3484 - val_accuracy: 0.8555\n",
            "Epoch 168/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8646 - val_loss: 0.3491 - val_accuracy: 0.8575\n",
            "Epoch 169/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3282 - accuracy: 0.8645 - val_loss: 0.3505 - val_accuracy: 0.8555\n",
            "Epoch 170/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3281 - accuracy: 0.8641 - val_loss: 0.3489 - val_accuracy: 0.8565\n",
            "Epoch 171/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8629 - val_loss: 0.3507 - val_accuracy: 0.8565\n",
            "Epoch 172/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3278 - accuracy: 0.8648 - val_loss: 0.3501 - val_accuracy: 0.8565\n",
            "Epoch 173/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3279 - accuracy: 0.8640 - val_loss: 0.3493 - val_accuracy: 0.8540\n",
            "Epoch 174/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8631 - val_loss: 0.3496 - val_accuracy: 0.8565\n",
            "Epoch 175/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8650 - val_loss: 0.3504 - val_accuracy: 0.8565\n",
            "Epoch 176/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3286 - accuracy: 0.8648 - val_loss: 0.3526 - val_accuracy: 0.8550\n",
            "Epoch 177/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8624 - val_loss: 0.3491 - val_accuracy: 0.8555\n",
            "Epoch 178/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3280 - accuracy: 0.8641 - val_loss: 0.3496 - val_accuracy: 0.8570\n",
            "Epoch 179/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8649 - val_loss: 0.3473 - val_accuracy: 0.8550\n",
            "Epoch 180/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8649 - val_loss: 0.3571 - val_accuracy: 0.8560\n",
            "Epoch 181/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3286 - accuracy: 0.8651 - val_loss: 0.3496 - val_accuracy: 0.8545\n",
            "Epoch 182/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8633 - val_loss: 0.3505 - val_accuracy: 0.8605\n",
            "Epoch 183/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8655 - val_loss: 0.3480 - val_accuracy: 0.8575\n",
            "Epoch 184/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3282 - accuracy: 0.8666 - val_loss: 0.3504 - val_accuracy: 0.8560\n",
            "Epoch 185/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3278 - accuracy: 0.8660 - val_loss: 0.3502 - val_accuracy: 0.8545\n",
            "Epoch 186/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3282 - accuracy: 0.8649 - val_loss: 0.3495 - val_accuracy: 0.8515\n",
            "Epoch 187/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3274 - accuracy: 0.8662 - val_loss: 0.3479 - val_accuracy: 0.8555\n",
            "Epoch 188/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3277 - accuracy: 0.8652 - val_loss: 0.3502 - val_accuracy: 0.8580\n",
            "Epoch 189/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.8664 - val_loss: 0.3501 - val_accuracy: 0.8535\n",
            "Epoch 190/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3277 - accuracy: 0.8641 - val_loss: 0.3511 - val_accuracy: 0.8545\n",
            "Epoch 191/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8649 - val_loss: 0.3518 - val_accuracy: 0.8530\n",
            "Epoch 192/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3278 - accuracy: 0.8656 - val_loss: 0.3496 - val_accuracy: 0.8515\n",
            "Epoch 193/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8644 - val_loss: 0.3502 - val_accuracy: 0.8565\n",
            "Epoch 194/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3283 - accuracy: 0.8643 - val_loss: 0.3484 - val_accuracy: 0.8525\n",
            "Epoch 195/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3279 - accuracy: 0.8655 - val_loss: 0.3537 - val_accuracy: 0.8630\n",
            "Epoch 196/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3279 - accuracy: 0.8645 - val_loss: 0.3485 - val_accuracy: 0.8530\n",
            "Epoch 197/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3284 - accuracy: 0.8637 - val_loss: 0.3477 - val_accuracy: 0.8575\n",
            "Epoch 198/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3279 - accuracy: 0.8649 - val_loss: 0.3496 - val_accuracy: 0.8570\n",
            "Epoch 199/200\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3275 - accuracy: 0.8651 - val_loss: 0.3496 - val_accuracy: 0.8560\n",
            "Epoch 200/200\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3282 - accuracy: 0.8648 - val_loss: 0.3495 - val_accuracy: 0.8555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['accuracy','validation_accuracy','loss','validation_loss'])\n",
        "plt.title('model accuray')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ok3sIN6mlfcO",
        "outputId": "20332b78-ea5f-46b4-9c58-634bd19efe4b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save your model to use later\n",
        "model.save('/content/drive/MyDrive/churn_model.h5')"
      ],
      "metadata": {
        "id": "9Hko85itlffl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the confusion matrix"
      ],
      "metadata": {
        "id": "9IP_FvmKofzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow confusion matrix of the model\n",
        "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred)"
      ],
      "metadata": {
        "id": "TVikumPegCoj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "# plot the confusion matrix using heatmap() method from seaborn\n",
        "plt.figure(figsize=(12,8))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.ylabel('PREDICTED')\n",
        "plt.xlabel('TRUTH')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "FywwnoRTgJ17",
        "outputId": "b55dda15-2d0e-497e-a134-ba981ff9a323"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}