{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4507b1d1",
   "metadata": {},
   "source": [
    "# Scraping apec webpage (www.apec.fr) with SELENIUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0790662",
   "metadata": {},
   "source": [
    "### Web crawling Vs. Web scraping\n",
    "- __Web crawling__, also known as Indexing is used to index the information on the page using bots also known as crawlers. Crawling is essentially what search engines do. It’s all about viewing a page as a whole and indexing it. When a bot crawls a website, it goes through every page and every link, until the last line of the website, looking for ANY information. Web Crawlers are basically used by major search engines like Google, Bing, Yahoo, statistical agencies, and large online aggregators.\n",
    "\n",
    "- __Web scraping__, also known as web data extraction, is similar to web crawling in that it identifies and locates the target data from web pages. __The key difference, is that with web scraping, we know the exact data set identifier__ e.g. an HTML element structure for web pages that are being fixed, from which data needs to be extracted. Web scraping is an automated way of extracting specific data sets using bots which are also known as ‘scrapers’. Once the desired information is collected it can be used for comparison, verification, and analysis based on a given business’s needs and goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d3c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules:\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import time, sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d4fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the the executable link path\n",
    "link_path = Service('/Users/elhadji/Desktop/Python_Labs/chromedriver')\n",
    "# Creating the “driver”\n",
    "driver =  webdriver.Chrome(service=link_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e535d2b",
   "metadata": {},
   "source": [
    "## Create a function to generate a list urls of webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afee9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to build the url list of wepages\n",
    "def build_ful_apecurl(keyword_list, pages_numb):\n",
    "    # Add %20 join strings in keywordlist\n",
    "    str_keyword = '%20'.join(keyword_list)\n",
    "    # set apec web page as string variable\n",
    "    root_url = \"https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=\"\n",
    "    # url page\n",
    "    url_page = '&page='\n",
    "    # empty list store full url or each wbepage\n",
    "    apec_url_list = []\n",
    "    # full url by contenating in the following list\n",
    "    for n in pages_numb:\n",
    "        apec_url_list.append(root_url+str_keyword+url_page+str(n))\n",
    "    return apec_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbfa585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword to seach a keyword : \"data scientist\" as list two items\n",
    "keyword_list = ['data', 'scientist']\n",
    "# Page numbers list \n",
    "pages_numb = [n for n in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3120f3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data%20scientist&page=0',\n",
       " 'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data%20scientist&page=1',\n",
       " 'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data%20scientist&page=2',\n",
       " 'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data%20scientist&page=3',\n",
       " 'https://www.apec.fr/candidat/recherche-emploi.html/emploi?motsCles=data%20scientist&page=4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the list of five pages\n",
    "my_apec_links = build_ful_apecurl(keyword_list, pages_numb)\n",
    "# Print to see \n",
    "my_apec_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c68746d",
   "metadata": {},
   "source": [
    "## Create function to extract data by tagname, class_name, css_selector, xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1dacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratct job titles with driver.find_elements By.TAG_NAME()\n",
    "def job_title_extractor_tagname(url_list, tag):\n",
    "    \"\"\"\n",
    "    Take an url list and a tag and return all jobs the given webpage\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "    # loop thorought urls and extract job title by h2 tag\n",
    "    for url in url_list:\n",
    "        driver.get(url)\n",
    "        all_h2 = driver.find_elements(By.TAG_NAME,tag)\n",
    "        all_jobs += [element.text for element in all_h2]\n",
    "    # return all_jobs\n",
    "    return all_jobs\n",
    "# Probem : It scraps any 'h2' element in the welpage including job titles and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8246c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job title tag : 'h2'\n",
    "tag = \"h2\"\n",
    "# get all job titles\n",
    "job_titles = job_title_extractor_tagname(my_apec_links, tag)\n",
    "# check the lenght of the list\n",
    "len(job_titles) \n",
    "# Include all h2 elements (job title + other section titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6695031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extratct element with driver.find_elements by.CSS_SELECTOR() >  class_name\n",
    "def job_title_extractor_class(url_list, class_name):\n",
    "    \"\"\"\n",
    "    Take an url list and a class name to return all jobs from all webpages\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "    for url in url_list:\n",
    "        driver.get(url)\n",
    "        all_class = driver.find_elements(By.CSS_SELECTOR,class_name)\n",
    "        all_jobs += [element.text for element in all_class]\n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624e39bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class name value and extract element by.CSS_SELECTOR()\n",
    "class_name = \".card-title.fs-16\"\n",
    "job_titles = job_title_extractor_class(my_apec_links, class_name) # better than TAG_NAME(), more specific !!!\n",
    "# Check the lenght of the list\n",
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24e9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SCIENTIST F/H\n"
     ]
    }
   ],
   "source": [
    "# print the fourth element\n",
    "print(job_titles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds elements by XPATH\n",
    "def job_company_extractor(url_list, class_xpath):\n",
    "    \"\"\"\n",
    "    Take an url and an Xpath to return all job company in a webpage\n",
    "    \"\"\"\n",
    "    all_company = []\n",
    "    for url in url_list:\n",
    "        driver.get(url)\n",
    "        all_comp = driver.find_elements(By.XPATH, class_xpath)\n",
    "        all_company += [element.text for element in all_comp]\n",
    "    #driver.quit()\n",
    "    return all_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5549bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define company name's xpath\n",
    "class_xpath = \"//*[@class='card-offer__company mb-10']\" # company name\n",
    "# get all the companies' name\n",
    "job_company = job_company_extractor(my_apec_links, class_xpath)\n",
    "# check the lenght of their list\n",
    "len(job_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73cf675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUDIEL PARTICIPATIONS\n"
     ]
    }
   ],
   "source": [
    "# print the the fourth element\n",
    "print(job_company[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693467f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define 'salary' xpath \n",
    "xpath = '//ul[@class=\"details-offer\"]' # salary per year\n",
    "# get all the job details\n",
    "job_salary = job_company_extractor(my_apec_links,xpath)\n",
    "# check the lenght of their list\n",
    "len(job_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a660cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 - 43 k€ brut annuel\n"
     ]
    }
   ],
   "source": [
    "# print the fourth element\n",
    "print(job_salary[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b65c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job description by class name\n",
    "class_name = \".card-offer__description.mb-15\" \n",
    "# get the job descriptions\n",
    "job_descrition = job_title_extractor_class(my_apec_links, class_name) # using CSS_SELECTOR\n",
    "# check the lenght of their list\n",
    "len(job_descrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68e4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans le cadre d'une embauche, vous interviendrez en tant que data scientist. Vous analyserez de gros volumes de données de type série temporelle, développerez et déploierez des modèles prédictifs, et assurerez la communication avec le client. Vous contribuer également aux...\n"
     ]
    }
   ],
   "source": [
    "# printh the fourth element\n",
    "print(job_descrition[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92bceb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get job type, job location and published date \n",
    "class_name = \".details-offer.important-list\"\n",
    "# get this derails \n",
    "type_loc_date = job_title_extractor_class(my_apec_links, class_name) # using CSS_SELECTOR\n",
    "# check the lenght of their list\n",
    "len(type_loc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49463260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDI\n",
      "Blagnac - 31\n",
      "16/11/2021\n"
     ]
    }
   ],
   "source": [
    "# print the fourth element\n",
    "print(type_loc_date[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70bcf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CDI\\nBlagnac - 31\\n16/11/2021'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the fourth element\n",
    "type_loc_date[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bdb1c",
   "metadata": {},
   "source": [
    "### Create an unique function that can extract elements from mutiple classes by xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "555e6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds elements specially by XPATH\n",
    "def jobs_infos_extractor(url_list, xpath_class_list):\n",
    "    \"\"\"\n",
    "    Take an url and an Xpath to return all job infos (title, company, salary, description, ....) from each a webpage\n",
    "    \"\"\"\n",
    "    # Initiate jobs characteristics list\n",
    "    all_jobs = [] # job titles\n",
    "    all_company = [] # job companies\n",
    "    all_salary = [] # job salaries\n",
    "    all_description = [] # job descriptions\n",
    "    all_details = [] # job details (type, location, date)\n",
    "    \n",
    "    # loop throught the urls' list\n",
    "    for url in url_list:\n",
    "        driver.get(url)\n",
    "        # get titles\n",
    "        all_class = driver.find_elements(By.XPATH, xpath_class_list[0])\n",
    "        all_jobs += [element.text for element in all_class]\n",
    "        # get companies\n",
    "        all_comp = driver.find_elements(By.XPATH, xpath_class_list[1])\n",
    "        all_company += [element.text for element in all_comp]\n",
    "        # get salaries\n",
    "        all_sal = driver.find_elements(By.XPATH, xpath_class_list[2])\n",
    "        all_salary  += [element.text for element in all_sal]\n",
    "        # get descriptions\n",
    "        all_descrip = driver.find_elements(By.XPATH, xpath_class_list[3])\n",
    "        all_description += [element.text for element in all_descrip]\n",
    "        # get job details\n",
    "        all_det = driver.find_elements(By.XPATH, xpath_class_list[4])\n",
    "        all_details += [element.text for element in all_det]      \n",
    "    # return scrapped data\n",
    "    return (all_jobs, all_company, all_salary, all_description, all_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c14080d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that splits string into list to deal with job details\n",
    "def string_to_list(text):\n",
    "    return text.split(\"\\n\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcbb6803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CDI', 'Blagnac - 31', '16/11/2021']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing string to list function\n",
    "txt = 'CDI\\nBlagnac - 31\\n16/11/2021'\n",
    "string_to_list(txt) # It's working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e580613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert type_loc_date into a list of three elements\n",
    "job_det = [string_to_list(my_elem) for my_elem in type_loc_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56becc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each element and put it in list : type \"0\", location \"1\" or date \"2\"\n",
    "type_ = [job_type[0] for job_type in job_det] # contract type\n",
    "loc = [job_type[1] for job_type in job_det] # location\n",
    "dat = [job_type[2] for job_type in job_det] # date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7f79c",
   "metadata": {},
   "source": [
    "## Build a function that creates a csv file from data after scrapping the wedsite www.apec.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e517c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_apec_csv(keyword_list,xpath_class_list,pages_numb):\n",
    "    \"\"\"\n",
    "    Function that creates a dictionary with all the data scrapped from the apec website for data scientist postion\n",
    "    and stores it in a csv file.\n",
    "    \"\"\"\n",
    "    ###################################################################\n",
    "    # Build url bebpages' list\n",
    "    my_apec_links = build_ful_apecurl(keyword_list, pages_numb)\n",
    "    # Five job items to extract here\n",
    "    job_titles, job_company,job_salary,job_descrition,job_details = jobs_infos_extractor(my_apec_links, xpath_class_list)\n",
    "    # Transform job_details to extract type, loc and date\n",
    "    type_loc_date = [string_to_list(my_elem) for my_elem in job_details] # call string_to_list function\n",
    "    # Put type in a list\n",
    "    contract = [job_type[0] for job_type in type_loc_date]\n",
    "    # Put location in a list\n",
    "    location = [job_type[1] for job_type in type_loc_date]\n",
    "    # Put date in a list\n",
    "    date = [job_type[2] for job_type in type_loc_date]\n",
    "    \n",
    "    # create a dictionary to stucture the scrapped data\n",
    "    my_dict = {\"Job title\":job_titles, \"Company\":job_company, \"Salary\":job_salary, \"Description\":job_descrition,\n",
    "               \"Contract\":contract, \"Location\":location, \"date\":date}\n",
    "    \n",
    "    # create the dataframe with dict\n",
    "    data = pd.DataFrame(my_dict)\n",
    "    \n",
    "    # store scrapped data in csv file\n",
    "    data.to_csv('/Users/elhadji/Desktop/Python_Labs/aspec_ds_jobs_offers.csv', sep=\";\", encoding='utf-8', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cbfe9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniate the keyword list\n",
    "keyword_list = ['data', 'scientist']\n",
    "# Page numbers list \n",
    "pages_numb = [n for n in range(21)]\n",
    "# Xpath classes list\n",
    "xpath_class_list = ['//h2[@class=\"card-title fs-16\"]', \"//*[@class='card-offer__company mb-10']\",\n",
    "              '//ul[@class=\"details-offer\"]', '//p[@class=\"card-offer__description mb-15\"]', '//ul[@class=\"details-offer important-list\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a05fe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put apec offers data in csv\n",
    "build_apec_csv(keyword_list,xpath_class_list,pages_numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df711e",
   "metadata": {},
   "source": [
    "## Importing scrapped data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "943991a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the saved data with pandas\n",
    "df = pd.read_csv('/Users/elhadji/Desktop/Python_Labs/aspec_ds_jobs_offers.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d2d0e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Location</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>FULL DATA MANAGEMENT</td>\n",
       "      <td>35 - 45 k€ brut annuel</td>\n",
       "      <td>Dans le cadre de notre développement, nous rec...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Lille - 59</td>\n",
       "      <td>16/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>ROBERT WALTERS FRANCE</td>\n",
       "      <td>45 - 50 k€ brut annuel</td>\n",
       "      <td>Notre client, groupe spécialisé dans l'assuran...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Toulon - 83</td>\n",
       "      <td>10/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>TALENTS RH</td>\n",
       "      <td>45 - 50 k€ brut annuel</td>\n",
       "      <td>TALENTS RH, société de recrutement spécialisée...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Lille - 59</td>\n",
       "      <td>18/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST F/H</td>\n",
       "      <td>STUDIEL PARTICIPATIONS</td>\n",
       "      <td>35 - 43 k€ brut annuel</td>\n",
       "      <td>Dans le cadre d'une embauche, vous interviendr...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Blagnac - 31</td>\n",
       "      <td>16/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>REGIONSJOB</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>\"Recrutez au delà des compétences.\" PERSUADERS...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Lyon 01 - 69</td>\n",
       "      <td>26/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA SCIENTIST F/H</td>\n",
       "      <td>PREM CANAGARADJA</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>D’une manière générale, vous serez en charge d...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Toulouse - 31</td>\n",
       "      <td>19/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>YSANCE</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>En tant que Data Scientist, vous contribuerez ...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Levallois-Perret - 92</td>\n",
       "      <td>21/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>METEOJOB</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>A la recherche de nouvelles affinités professi...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Écully - 69</td>\n",
       "      <td>10/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>METEOJOB</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>Rattaché(e) à la Direction Générale Exécutive ...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Clichy - 92</td>\n",
       "      <td>23/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>SAS PROXIEL</td>\n",
       "      <td>A partir de 40 k€ brut annuel</td>\n",
       "      <td>Nous recherchons un Data Scientist (F/H) pour ...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Nice - 06</td>\n",
       "      <td>09/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist - F/H</td>\n",
       "      <td>ANSACONSULT</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>Votre mission si vous l’acceptez : Vous accomp...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Lille - 59</td>\n",
       "      <td>24/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>GROUPAMA ASSURANCES MUTUELLES</td>\n",
       "      <td>A partir de 20 k€ brut annuel</td>\n",
       "      <td>Au sein de la Direction Etudes Technique et Ta...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Nanterre - 92</td>\n",
       "      <td>16/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>ABIL INTERIM</td>\n",
       "      <td>35 - 38 k€ brut annuel</td>\n",
       "      <td>Vous travaillez sous la responsabilité du mana...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Montauban - 82</td>\n",
       "      <td>29/10/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>DASSAULT AVIATION</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>La Direction Générale du Soutien Militaire (DG...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Saint-Cloud - 92</td>\n",
       "      <td>05/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>AGAP2IT</td>\n",
       "      <td>A partir de 35 k€ brut annuel</td>\n",
       "      <td>Au sein d'une équipe de 10 personnes, vous ser...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Boulogne-Billancourt - 92</td>\n",
       "      <td>08/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>CLEEVEN SE</td>\n",
       "      <td>25 - 40 k€ brut annuel</td>\n",
       "      <td>Au sein de nos équipes de data science, nous r...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Biot - 06</td>\n",
       "      <td>24/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>REGIONSJOB</td>\n",
       "      <td>A négocier</td>\n",
       "      <td>Société indépendante comprenant 730 collaborat...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Villeurbanne - 69</td>\n",
       "      <td>26/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data scientist F/H</td>\n",
       "      <td>TALENTS IT</td>\n",
       "      <td>35 - 40 k€ brut annuel</td>\n",
       "      <td>LA SOCIÉTÉ Talents IT, cabinet de recrutement ...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Villeurbanne - 69</td>\n",
       "      <td>15/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data scientist F/H</td>\n",
       "      <td>TALENTS IT</td>\n",
       "      <td>35 - 40 k€ brut annuel</td>\n",
       "      <td>LA SOCIÉTÉ Talents IT, cabinet de recrutement ...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Villeurbanne - 69</td>\n",
       "      <td>09/11/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist F/H</td>\n",
       "      <td>CTS CORPORATE</td>\n",
       "      <td>30 - 35 k€ brut annuel</td>\n",
       "      <td>Dans le cadre du développement de nos activité...</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Marignane - 13</td>\n",
       "      <td>23/11/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Job title                        Company  \\\n",
       "0     Data Scientist F/H           FULL DATA MANAGEMENT   \n",
       "1     Data Scientist F/H          ROBERT WALTERS FRANCE   \n",
       "2     Data Scientist F/H                     TALENTS RH   \n",
       "3     DATA SCIENTIST F/H         STUDIEL PARTICIPATIONS   \n",
       "4     Data Scientist F/H                     REGIONSJOB   \n",
       "5     DATA SCIENTIST F/H               PREM CANAGARADJA   \n",
       "6     Data Scientist F/H                         YSANCE   \n",
       "7     Data Scientist F/H                       METEOJOB   \n",
       "8     Data Scientist F/H                       METEOJOB   \n",
       "9     Data Scientist F/H                    SAS PROXIEL   \n",
       "10  Data Scientist - F/H                    ANSACONSULT   \n",
       "11    Data Scientist F/H  GROUPAMA ASSURANCES MUTUELLES   \n",
       "12    Data Scientist F/H                   ABIL INTERIM   \n",
       "13    Data Scientist F/H              DASSAULT AVIATION   \n",
       "14    Data Scientist F/H                        AGAP2IT   \n",
       "15    Data Scientist F/H                     CLEEVEN SE   \n",
       "16    Data Scientist F/H                     REGIONSJOB   \n",
       "17    Data scientist F/H                     TALENTS IT   \n",
       "18    Data scientist F/H                     TALENTS IT   \n",
       "19    Data Scientist F/H                  CTS CORPORATE   \n",
       "\n",
       "                           Salary  \\\n",
       "0          35 - 45 k€ brut annuel   \n",
       "1          45 - 50 k€ brut annuel   \n",
       "2          45 - 50 k€ brut annuel   \n",
       "3          35 - 43 k€ brut annuel   \n",
       "4                      A négocier   \n",
       "5                      A négocier   \n",
       "6                      A négocier   \n",
       "7                      A négocier   \n",
       "8                      A négocier   \n",
       "9   A partir de 40 k€ brut annuel   \n",
       "10                     A négocier   \n",
       "11  A partir de 20 k€ brut annuel   \n",
       "12         35 - 38 k€ brut annuel   \n",
       "13                     A négocier   \n",
       "14  A partir de 35 k€ brut annuel   \n",
       "15         25 - 40 k€ brut annuel   \n",
       "16                     A négocier   \n",
       "17         35 - 40 k€ brut annuel   \n",
       "18         35 - 40 k€ brut annuel   \n",
       "19         30 - 35 k€ brut annuel   \n",
       "\n",
       "                                          Description Contract  \\\n",
       "0   Dans le cadre de notre développement, nous rec...      CDI   \n",
       "1   Notre client, groupe spécialisé dans l'assuran...      CDI   \n",
       "2   TALENTS RH, société de recrutement spécialisée...      CDI   \n",
       "3   Dans le cadre d'une embauche, vous interviendr...      CDI   \n",
       "4   \"Recrutez au delà des compétences.\" PERSUADERS...      CDI   \n",
       "5   D’une manière générale, vous serez en charge d...      CDI   \n",
       "6   En tant que Data Scientist, vous contribuerez ...      CDI   \n",
       "7   A la recherche de nouvelles affinités professi...      CDI   \n",
       "8   Rattaché(e) à la Direction Générale Exécutive ...      CDI   \n",
       "9   Nous recherchons un Data Scientist (F/H) pour ...      CDI   \n",
       "10  Votre mission si vous l’acceptez : Vous accomp...      CDI   \n",
       "11  Au sein de la Direction Etudes Technique et Ta...      CDI   \n",
       "12  Vous travaillez sous la responsabilité du mana...      CDI   \n",
       "13  La Direction Générale du Soutien Militaire (DG...      CDI   \n",
       "14  Au sein d'une équipe de 10 personnes, vous ser...      CDI   \n",
       "15  Au sein de nos équipes de data science, nous r...      CDI   \n",
       "16  Société indépendante comprenant 730 collaborat...      CDI   \n",
       "17  LA SOCIÉTÉ Talents IT, cabinet de recrutement ...      CDI   \n",
       "18  LA SOCIÉTÉ Talents IT, cabinet de recrutement ...      CDI   \n",
       "19  Dans le cadre du développement de nos activité...      CDI   \n",
       "\n",
       "                     Location        date  \n",
       "0                  Lille - 59  16/11/2021  \n",
       "1                 Toulon - 83  10/11/2021  \n",
       "2                  Lille - 59  18/11/2021  \n",
       "3                Blagnac - 31  16/11/2021  \n",
       "4                Lyon 01 - 69  26/11/2021  \n",
       "5               Toulouse - 31  19/11/2021  \n",
       "6       Levallois-Perret - 92  21/11/2021  \n",
       "7                 Écully - 69  10/11/2021  \n",
       "8                 Clichy - 92  23/11/2021  \n",
       "9                   Nice - 06  09/11/2021  \n",
       "10                 Lille - 59  24/11/2021  \n",
       "11              Nanterre - 92  16/11/2021  \n",
       "12             Montauban - 82  29/10/2021  \n",
       "13           Saint-Cloud - 92  05/11/2021  \n",
       "14  Boulogne-Billancourt - 92  08/11/2021  \n",
       "15                  Biot - 06  24/11/2021  \n",
       "16          Villeurbanne - 69  26/11/2021  \n",
       "17          Villeurbanne - 69  15/11/2021  \n",
       "18          Villeurbanne - 69  09/11/2021  \n",
       "19             Marignane - 13  23/11/2021  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prin the 20 first rows\n",
    "df.head(20) # 15 firts offers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
